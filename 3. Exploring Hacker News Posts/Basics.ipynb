{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hacker News Porject\n",
    "In this project, we'll work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/).\n",
    "\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that we have reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: the unique identifier from Hacker News for the post\n",
    "- `title`: the title of the post\n",
    "- `url`: the URL that the posts links to, if the post has a URL\n",
    "- `num_points`: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: the number of comments on the post\n",
    "- `author`: the username of the person who submitted the post\n",
    "- `created_at`: the date and time of the post's submission\n",
    "\n",
    "We're specifically interested in posts with titles that begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. \n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Slide 1: Reading the CSV file and assigning to variable \n",
    "\n",
    "from csv import reader  # if we do not want to use pandas, we can use the \"csv\" library and import reader from it\n",
    "opened = open (\"hacker_news.csv\")\n",
    "hn = list (reader (opened)) #reading as a list of lists\n",
    "print(hn[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'], ['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']]\n"
     ]
    }
   ],
   "source": [
    "#Slide 2: Extracting the first row of data and assigning it to the header\n",
    "\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "print(hn[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "To find the posts that begin with either Ask HN or Show HN, we'll use the string method `startswith`. Given a string object, say, string1, we can check if starts with, say, dq by inspecting the output of the object string1.startswith('dq'). If string1 starts with dq, it will return True; otherwise, it will return False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask posts =  1744\n",
      "show posts =  1162\n",
      "other posts =  17194\n"
     ]
    }
   ],
   "source": [
    "#Slide 3: Using startswith string method to put the posts in appropriate bins.\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(\"ask posts = \",len(ask_posts))\n",
    "print(\"show posts = \",len(show_posts))\n",
    "print(\"other posts = \",len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ask comments is: 14.038417431192661\n",
      "average show comments is: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "#Slide 4: Finding the total number of comments on the ask posts. \n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row [4]) #num_comments is index 4\n",
    "\n",
    "#calculating the avg ask comments\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts) \n",
    "print(\"average ask comments is:\",avg_ask_comments)\n",
    "\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row [4]) #num_comments is index 4\n",
    "\n",
    "#calculating the avg show comments\n",
    "avg_show_comments = total_show_comments/len(show_posts) \n",
    "print(\"average show comments is:\",avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above investigation shows that on avergae the ask posts have 4 more comments than the show posts. The average ask post gets around 14 comments, where as the average show post gets only 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment by hour  {'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n",
      "\n",
      "\n",
      "counts by hour {'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "#Slide 5: Finding the number of ask posts and comments by hour created using the \n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "\n",
    "for row in ask_posts:\n",
    "    \n",
    "    result_list.append(row[7:3:-2]) # Slicing the larger list to get the create time and comments \n",
    "    ###but I have not made the second element to int yet.\n",
    "    ###I could go: which gives the int for the comment number\n",
    "#     temp = []\n",
    "#     temp.append(row[6])\n",
    "#     temp.append(int(row[4]))\n",
    "#     result_list.append(temp)\n",
    "        \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "#print(result_list[0:3])\n",
    "\n",
    "date_format = (\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "for row in result_list:\n",
    "    date_time =  dt.datetime.strptime(row[0], date_format)\n",
    "    time = dt.datetime.strftime(date_time, \"%H\")\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = int(row[1])       \n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += int(row[1]) \n",
    "\n",
    "\n",
    "    \n",
    "print(\"comment by hour \",comments_by_hour)\n",
    "print('\\n')\n",
    "print(\"counts by hour\",counts_by_hour)\n",
    "\n",
    "# counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "# comments_by_hour: contains the corresponding number of comments ask posts created at each hour received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average comments per post by the hour is: [['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298]]\n"
     ]
    }
   ],
   "source": [
    "#Slide 6: Doing the avergae operation on all the vlaues in the dictionary and returning the result as a list of lists. \n",
    "\n",
    "avg_by_hour =[]\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "print(\"average comments per post by the hour is:\",avg_by_hour[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it difficult to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13']]\n",
      "Other method:--\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "#Slide 7: Sorting and finding out the highest values.\n",
    "\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:  #used the \"temp\" trick learnt form answers, but the slicing is a lot better.\n",
    "    temp = []\n",
    "    temp.append(row[1])\n",
    "    temp.append(row[0])\n",
    "    swap_avg_by_hour.append(temp)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "print(sorted_swap[0:6])\n",
    "print(\"Other method:--\")\n",
    "\n",
    "# Different method, using string formatting.\n",
    "for row in sorted_swap[0:5]:\n",
    "    hour_prsd = dt.datetime.strptime(row[1],\"%H\")\n",
    "    hour_frmtd = dt.datetime.strftime(hour_prsd,\"%H:00\")\n",
    "    \n",
    "    #print(hour_frmtd)\n",
    "    \n",
    "\n",
    "    my_str = \"{}: {:.2f} average comments per post\"\n",
    "    output = my_str.format(hour_frmtd,row[0])\n",
    "    print(output)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:** Data set has US eastern time. I am in Dubai which is 8 hours AHEAD of US easternn time, so the highest post for me would be 23:00 (11pm) local dubai time. The next highest is 10 am dubai time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
